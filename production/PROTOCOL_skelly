#!/bin/bash
#SBATCH --time=(RUNTIME):00:00
#SBATCH --partition=(PART)
#SBATCH --qos=(QOS)
#SBATCH --ntasks-per-socket=(GPUS) --gres=gpu:(GPUS) --tasks=(GPUS)
#SBATCH --constraint="GPU_SKU:TITAN_Xp|GPU_SKU:TITAN_X"
#SBATCH --mem=1GB
#SBATCH --output=(REV)slurm.out --open-mode=append
##SBATCH --mail-user=(WHOAMI)@stanford.edu --mail-type=FAIL
#SBATCH --job-name=(NAM)_prod_(REP)
#
#
#=====================================================================
#                            PROTOCOL(REV)
#=====================================================================
# GOAL   : Simulate
# INPUTS :
# OUTPUT : 
# PROJECT: (NAM)
# PATH   : (DIR) 
# DATE   : (NOW)
#=====================================================================
#

# Exit if any command fails
set -e

# Protocol revision number
rev="(REV)"
rep="(REP)"

# Directory containing mdin files (one directory up)
inpdir="(INP)"
cd "$inpdir/$rep"

# Symlinked the output from previous run to be the input here,
# and symlinked the prmtop from the preparation step
prmtop="(PRMTOP)"
ref="(REF)"

# Load necessary modules
source "$PI_HOME/software/amber_dev/setup_amber.sh"

# Source the common run functions and print some info
. (FUNFILE)
print_node_jobs

# Check for P2P GPUs. Fail if not
if [[ "$SLURM_NTASKS_PER_SOCKET" -gt 1 ]]; then
    p2p=$((P2P))
    if [[ "$p2p" == *"NO"* ]]; then
      echo "ERROR! Didn't get P2P GPUs!"
      echo "HOSTNAME             = $HOSTNAME"
      echo "CUDA VISIBLE DEVICES = $CUDA_VISIBLE_DEVICES"
      exit 1
    fi
fi

# Do last equilibration step in each replicate
# Remove restraints entirely, equilibrate for 5ns
# in the NPT ensemble, 2.5fs timestep
if [[ ! -f "Eq_6.rst" ]]; then
    echo "No restraint equilibration for initial run: $SLURM_JOB_NAME"
    rm -f "Prod_"*
    check_previous "(EQDIR)/Eq_final.mdout" "Eq_final"
    run_md "Eq_6" "(EQDIR)/Eq_final.rst" "$inpdir/Eq_6.mdin" nochmod
fi

# Simulate at 310K in the NPT ensemble with 2.0fs timestep
# This run will probably run out of walltime.
if [[ ! -f "Prod_0.rst" ]]; then
    echo "Beginning first unrestrained production run: $SLURM_JOB_NAME"
    check_previous "Eq_6.mdout" "Eq_6" # Check equilibration completed successfully
    run_md "Prod_0" "Eq_6.rst" "$inpdir/Prod_(RUNTIME)h.mdin"
fi

# Given final equilibration and initial production run, continue from here
last=$(ls -1 $inpdir/$rep/Prod*rst | sed -E -e "s@Prod_?@@" -e "s@.rst@@" -e "s@$inpdir/$rep/@@g" | sort -n | tail -n 1)

# Check for successful completion
check_previous "Prod_${last}.mdout" "Prod_${last}" nofail

# Recalculate last in case it changed
last=$(ls -1 $inpdir/$rep/Prod*rst | sed -E -e "s@Prod_?@@" -e "s@.rst@@" -e "s@$inpdir/$rep/@@g" | sort -n | tail -n 1)
rst="$inpdir/$rep/Prod_${last}.rst"

# Check that last actually exists. If Prod_0 was wrong and deleted, it could be empty
if [[ -z $last ]] || [[ ! -f $rst ]]; then
    echo "No such production restart: $rst. Aborting to re-equilibrate."
    rm -f "Eq_6"*
    exit 1
fi

# Remove write permissions for the previously completed trajectory
# Only if it completed successfully
# Fail silently if there is a permissions error
if [[ -f "Prod_${last}.rst" && -s "Prod_${last}.rst" ]]; then
    set +e
    chmod a-w -f "Prod_${last}"*
    set -e
fi

# Now start working on the next trajectory
last=$((last+1))

# Simulate at 310K in the NPT ensemble with 2.0fs timestep
# This run will probably run out of walltime.
echo "Beginning run: $SLURM_JOB_NAME trajectory number: $last"
run_md "Prod_${last}" "$rst" "$inpdir/Prod_(RUNTIME)h.mdin"

# Total equilibration now performed.
echo "Done with run: $SLURM_JOB_NAME"

